<!doctype html>
<html>

<head>
    <title>Stable Diffusion Image Grid - Info</title>
</head>

<body>
    <h1>About this project</h1>
    <a href="index.html">Return to main page</a>

    <h2>Credits</h2>

    <p>Inspired by <a href="https://generrated.com/">https://generrated.com</a> which did this for DALL-E 2,
        and from which I took all the topics and most styles. Partly out of laziness, but also to allow comparing
        results between these two projects.</p>

    <p>That version has much nicer UI, but this one has reproducible results and consistent seed across images
        which leads to interesting effects.</p>

    <p>Second major source of prompts was <a href="https://rexwang8.github.io/resource/ai/teapot">this amazing
            collection of teapots</a>.</p>

    <p>Additional prompt suggestions and fixes by Reddit users in <a
            href="https://old.reddit.com/r/StableDiffusion/comments/xwi2pm">this thread</a>.</p>

    <h2>Source</h2>
    <a href="https://github.com/lacop/sdgrid">https://github.com/lacop/sdgrid</a>

    <h2>Reproducible results</h2>
    All images use the seeds <code>42, 43, 44, 45</code>. Settings used: 75 steps, 512x512, LMS sampler, scale 7.
    <br>
    The version of the SD repository is referenced in the Github README.
    You should be able to reproduce all the images.

    <h2>How long did it take?</h2>
    Images were generated on a single GCP instance with NVIDIA A100 40GB with <code>batch_size=4</code>
    (the largest size before diminishing returns), each prompt taking around 12 seconds
    to generate four images. Do the math :)

    <h2>Prompt suggestions, feature requests, bug fixes?</h2>
    Feel free to open an issue or (even better) send a pull request. But please note this is a small weekend project, I
    might not have time to do what you want. You can always fork it!
</body>

</html>